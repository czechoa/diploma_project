{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from dash_app.backend.db_dictonary import load_datasets\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "db_dictonary = load_datasets()\n",
    "db_dictonary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: polemo2-official/all_text\n",
      "Found cached dataset polemo2-official (/home/andrzej/.cache/huggingface/datasets/clarin-pl___polemo2-official/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "147ed90c2f524302939e12171ed06b97"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/andrzej/.cache/huggingface/datasets/clarin-pl___polemo2-official/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70/cache-b6a1b952987bead8.arrow\n",
      "Loading cached processed dataset at /home/andrzej/.cache/huggingface/datasets/clarin-pl___polemo2-official/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70/cache-6db3c2276b67bcd3.arrow\n",
      "Loading cached processed dataset at /home/andrzej/.cache/huggingface/datasets/clarin-pl___polemo2-official/all_text/0.0.0/2b75fdbe5def97538e81fb120f8752744b50729a4ce09bd75132bfc863a2fd70/cache-a134f64418ef98a1.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'target'],\n        num_rows: 6573\n    })\n    validation: Dataset({\n        features: ['text', 'target'],\n        num_rows: 823\n    })\n    test: Dataset({\n        features: ['text', 'target'],\n        num_rows: 820\n    })\n})"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "from dash_app.backend.utils.prepared_date import add_maper_values_to_mapper_function\n",
    "from datasets import load_dataset\n",
    "from dash_app.backend.utils.object.dataset import DataSet\n",
    "\n",
    "name = \"clarin-pl/polemo2-official\"\n",
    "mapper_values= {1: 'negatywne', 3: 'dwuznaczne', 0: 'neutralne', 2: 'pozytywne'}\n",
    "target_col = 'target'\n",
    "dataDict = load_dataset(name)\n",
    "\n",
    "mapper_function = add_maper_values_to_mapper_function(mapper_values, target_col)\n",
    "\n",
    "dataDict = dataDict.map(mapper_function, num_proc=psutil.cpu_count(logical=True), load_from_cache_file=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: polemo2-official/all_text\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1695aa2a65794410ac4d42b03d0698ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['text', 'target'],\n    num_rows: 6573\n})"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset_builder\n",
    "dataset_builder = load_dataset_builder(name)\n",
    "dataset_builder.as_dataset()['train']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_data = db_dictonary['połączone'].data\n",
    "train = merged_data['train'].to_pandas()\n",
    "validation = merged_data['validation'].to_pandas()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To unidecode"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import unidecode\n",
    "\n",
    "mapper_target_value = {\n",
    "    'negatywne': 0,\n",
    "    'pozytywne': 1,\n",
    "}\n",
    "\n",
    "texts_org = train['token_tekst'].str.join(\" \")\n",
    "texts = texts_org.apply(unidecode.unidecode)\n",
    "\n",
    "texts_val = validation['token_tekst'].str.join(\" \")\n",
    "\n",
    "target = list(map(lambda x: mapper_target_value[x], train['ocena_tekst']))\n",
    "target_val = list(map(lambda x: mapper_target_value[x], validation['ocena_tekst']))\n",
    "\n",
    "texts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(texts_org[texts_org.str.contains('눉gdybym')].iloc[0])\n",
    "print(texts_org[texts.str.contains('zzerac')].iloc[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(encoding='ascii', strip_accents='ascii', min_df=1)\n",
    "X = vectorizer.fit_transform(texts)\n",
    "# print(X.toarray().sum().sum())\n",
    "vectorizer.get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target.value_counts() / target.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(strip_accents='ascii', min_df=2)),\n",
    "        (\"tfidf\", TfidfTransformer()),\n",
    "        # (\"clf\", LogisticRegression()),\n",
    "        ('clf', MultinomialNB()),\n",
    "    ]\n",
    ")\n",
    "text_clf.fit(texts, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__min_df': [1, 2],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1, scoring='f1')\n",
    "gs_clf = gs_clf.fit(texts, target)\n",
    "print(gs_clf.best_score_)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(strip_accents='ascii', min_df=1, ngram_range=(1, 2))),\n",
    "        (\"tfidf\", TfidfTransformer(use_idf=False)),\n",
    "        ('clf', MultinomialNB(alpha =0.01)),\n",
    "    ]\n",
    ")\n",
    "text_clf.fit(texts, target)\n",
    "\n",
    "y_pred = text_clf.predict(texts_val)\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def plot_and_print_score_model(target_val, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_true=target_val, y_pred=y_pred)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "    plt.xlabel('Predictions', fontsize=18)\n",
    "    plt.ylabel('Actuals', fontsize=18)\n",
    "    plt.title('Confusion Matrix', fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "    print('Precision: %.3f' % precision_score(target_val, y_pred))  # Precision Score = TP / (FP + TP)\n",
    "    print('Recall: %.3f' % recall_score(target_val, y_pred))  # Recall Score = TP / (FN + TP)\n",
    "    print('Accuracy: %.3f' % accuracy_score(target_val, y_pred))  # Accuracy Score = (TP + TN)/ (TP + FN + TN + FP)\n",
    "    print('F1 Score: %.3f' % f1_score(target_val,\n",
    "                                      y_pred))  # F1 Score = 2* Precision Score * Recall Score/ (Precision Score + Recall Score/)\n",
    "    print(metrics.classification_report(target_val, y_pred, target_names=mapper_target_value.keys()))\n",
    "\n",
    "\n",
    "# plot_and_print_score_model(target_val, y_pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "text_clf = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(strip_accents='ascii', min_df=1, ngram_range=(1, 2))),\n",
    "        (\"tfidf\", TfidfTransformer(use_idf=False)),\n",
    "         ('clf', LogisticRegression(class_weight='balance',max_iter=1000)),\n",
    "    ])\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__min_df': [1, 2],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__C': (1,10,100)\n",
    "\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1, scoring='f1')\n",
    "gs_clf = gs_clf.fit(texts, target)\n",
    "print(gs_clf.best_score_)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(strip_accents='ascii', min_df=2, ngram_range=(1, 2))),\n",
    "        (\"tfidf\", TfidfTransformer(use_idf=False)),\n",
    "        ('clf', LogisticRegression(C=10,class_weight='balance')),\n",
    "    ])\n",
    "\n",
    "text_clf.fit(texts, target)\n",
    "\n",
    "y_pred = text_clf.predict(texts_val)\n",
    "plot_and_print_score_model(target_val, y_pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}